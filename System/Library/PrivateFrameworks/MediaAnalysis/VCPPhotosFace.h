//
//     Generated by classdumpios 4.2.0 (64 bit).
//
//  Copyright (C) 1997-2019 Steve Nygard. Updated in 2022 by Kevin Bradley.
//

#import <objc/NSObject.h>

@class NSString, VCPVNImageprintWrapper;

__attribute__((visibility("hidden")))
@interface VCPPhotosFace : NSObject
{
    _Bool _hidden;	// 8 = 0x8
    _Bool _isInTrash;	// 9 = 0x9
    _Bool _manual;	// 10 = 0xa
    _Bool _isTooSmall;	// 11 = 0xb
    _Bool _hasSmile;	// 12 = 0xc
    _Bool _isLeftEyeClosed;	// 13 = 0xd
    _Bool _isRightEyeClosed;	// 14 = 0xe
    _Bool _hasFaceMask;	// 15 = 0xf
    short _detectionType;	// 16 = 0x10
    unsigned short _ageType;	// 18 = 0x12
    unsigned short _sexType;	// 20 = 0x14
    unsigned short _eyesState;	// 22 = 0x16
    unsigned short _smileType;	// 24 = 0x18
    unsigned short _facialHairType;	// 26 = 0x1a
    unsigned short _hairColorType;	// 28 = 0x1c
    unsigned short _glassesType;	// 30 = 0x1e
    unsigned short _expressionType;	// 32 = 0x20
    unsigned short _headgearType;	// 34 = 0x22
    unsigned short _hairType;	// 36 = 0x24
    unsigned short _poseType;	// 38 = 0x26
    unsigned short _skintoneType;	// 40 = 0x28
    unsigned short _ethnicityType;	// 42 = 0x2a
    unsigned short _gazeType;	// 44 = 0x2c
    int _trainingType;	// 48 = 0x30
    NSString *_localIdentifier;	// 56 = 0x38
    NSString *_personLocalIdentifier;	// 64 = 0x40
    long long _sourceWidth;	// 72 = 0x48
    long long _sourceHeight;	// 80 = 0x50
    double _centerX;	// 88 = 0x58
    double _centerY;	// 96 = 0x60
    double _size;	// 104 = 0x68
    double _bodyCenterX;	// 112 = 0x70
    double _bodyCenterY;	// 120 = 0x78
    double _bodyWidth;	// 128 = 0x80
    double _bodyHeight;	// 136 = 0x88
    double _blurScore;	// 144 = 0x90
    double _exposureScore;	// 152 = 0x98
    NSString *_adjustmentVersion;	// 160 = 0xa0
    long long _nameSource;	// 168 = 0xa8
    double _poseYaw;	// 176 = 0xb0
    unsigned long long _algorithmVersion;	// 184 = 0xb8
    long long _clusterSequenceNumber;	// 192 = 0xc0
    long long _qualityMeasure;	// 200 = 0xc8
    double _gazeCenterX;	// 208 = 0xd0
    double _gazeCenterY;	// 216 = 0xd8
    NSString *_groupingIdentifier;	// 224 = 0xe0
    VCPVNImageprintWrapper *_imageprintWrapper;	// 232 = 0xe8
    double _roll;	// 240 = 0xf0
    double _quality;	// 248 = 0xf8
}

+ (_Bool)_isColocatingAnimalObservation:(id)arg1 withFaceObservations:(id)arg2 orTorsoObservations:(id)arg3;	// IMP=0x0010000000059eba
+ (double)_calculateIoUBetweenObservation:(id)arg1 andObservation:(id)arg2;	// IMP=0x0010000000059d55
+ (double)_calculateOverlappingBetweenFaceObservation:(id)arg1 andHumanObservation:(id)arg2;	// IMP=0x0010000000059c45
+ (id)facesFromPHFetchResult:(id)arg1 copyOption:(long long)arg2;	// IMP=0x0010000000059364
+ (id)faceFromPHFace:(id)arg1 copyOption:(long long)arg2;	// IMP=0x0010000000058739
+ (id)facesFromFaceObservations:(id)arg1 humanObservations:(id)arg2 animalObservations:(id)arg3 sourceWidth:(unsigned long long)arg4 sourceHeight:(unsigned long long)arg5 visionRequests:(id)arg6 blurScorePerFace:(id)arg7 exposureScorePerFace:(id)arg8 tooSmallFaceObservations:(id)arg9 processingVersion:(int)arg10;	// IMP=0x00100000000560b7
+ (id)faceFromFaceObservation:(id)arg1 humanObservation:(id)arg2 sourceWidth:(unsigned long long)arg3 sourceHeight:(unsigned long long)arg4 visionRequests:(id)arg5 processingVersion:(int)arg6 force:(_Bool)arg7 andError:(id *)arg8;	// IMP=0x0010000000053a7f
+ (id)faceWithLocalIdentifier:(id)arg1;	// IMP=0x0010000000053a1a
- (void).cxx_destruct;	// IMP=0x000000000005ab64
@property(nonatomic) double quality; // @synthesize quality=_quality;
@property(nonatomic) double roll; // @synthesize roll=_roll;
@property(retain, nonatomic) VCPVNImageprintWrapper *imageprintWrapper; // @synthesize imageprintWrapper=_imageprintWrapper;
@property(copy, nonatomic) NSString *groupingIdentifier; // @synthesize groupingIdentifier=_groupingIdentifier;
@property(nonatomic) double gazeCenterY; // @synthesize gazeCenterY=_gazeCenterY;
@property(nonatomic) double gazeCenterX; // @synthesize gazeCenterX=_gazeCenterX;
@property(nonatomic) unsigned short gazeType; // @synthesize gazeType=_gazeType;
@property(nonatomic) _Bool hasFaceMask; // @synthesize hasFaceMask=_hasFaceMask;
@property(nonatomic) unsigned short ethnicityType; // @synthesize ethnicityType=_ethnicityType;
@property(nonatomic) unsigned short skintoneType; // @synthesize skintoneType=_skintoneType;
@property(nonatomic) unsigned short poseType; // @synthesize poseType=_poseType;
@property(nonatomic) unsigned short hairType; // @synthesize hairType=_hairType;
@property(nonatomic) unsigned short headgearType; // @synthesize headgearType=_headgearType;
@property(nonatomic) unsigned short expressionType; // @synthesize expressionType=_expressionType;
@property(nonatomic) unsigned short glassesType; // @synthesize glassesType=_glassesType;
@property(nonatomic) unsigned short hairColorType; // @synthesize hairColorType=_hairColorType;
@property(nonatomic) unsigned short facialHairType; // @synthesize facialHairType=_facialHairType;
@property(nonatomic) unsigned short smileType; // @synthesize smileType=_smileType;
@property(nonatomic) unsigned short eyesState; // @synthesize eyesState=_eyesState;
@property(nonatomic) unsigned short sexType; // @synthesize sexType=_sexType;
@property(nonatomic) unsigned short ageType; // @synthesize ageType=_ageType;
@property(nonatomic) long long qualityMeasure; // @synthesize qualityMeasure=_qualityMeasure;
@property(nonatomic) long long clusterSequenceNumber; // @synthesize clusterSequenceNumber=_clusterSequenceNumber;
@property(nonatomic) unsigned long long algorithmVersion; // @synthesize algorithmVersion=_algorithmVersion;
@property(nonatomic) double poseYaw; // @synthesize poseYaw=_poseYaw;
@property(nonatomic) int trainingType; // @synthesize trainingType=_trainingType;
@property(nonatomic) long long nameSource; // @synthesize nameSource=_nameSource;
@property(copy, nonatomic) NSString *adjustmentVersion; // @synthesize adjustmentVersion=_adjustmentVersion;
@property(nonatomic) _Bool isRightEyeClosed; // @synthesize isRightEyeClosed=_isRightEyeClosed;
@property(nonatomic) _Bool isLeftEyeClosed; // @synthesize isLeftEyeClosed=_isLeftEyeClosed;
@property(nonatomic) double exposureScore; // @synthesize exposureScore=_exposureScore;
@property(nonatomic) double blurScore; // @synthesize blurScore=_blurScore;
@property(nonatomic) _Bool hasSmile; // @synthesize hasSmile=_hasSmile;
@property(nonatomic) _Bool isTooSmall; // @synthesize isTooSmall=_isTooSmall;
@property(nonatomic) _Bool manual; // @synthesize manual=_manual;
@property(nonatomic) _Bool isInTrash; // @synthesize isInTrash=_isInTrash;
@property(nonatomic) _Bool hidden; // @synthesize hidden=_hidden;
@property(nonatomic) double bodyHeight; // @synthesize bodyHeight=_bodyHeight;
@property(nonatomic) double bodyWidth; // @synthesize bodyWidth=_bodyWidth;
@property(nonatomic) double bodyCenterY; // @synthesize bodyCenterY=_bodyCenterY;
@property(nonatomic) double bodyCenterX; // @synthesize bodyCenterX=_bodyCenterX;
@property(nonatomic) double size; // @synthesize size=_size;
@property(nonatomic) double centerY; // @synthesize centerY=_centerY;
@property(nonatomic) double centerX; // @synthesize centerX=_centerX;
@property(nonatomic) short detectionType; // @synthesize detectionType=_detectionType;
@property(nonatomic) long long sourceHeight; // @synthesize sourceHeight=_sourceHeight;
@property(nonatomic) long long sourceWidth; // @synthesize sourceWidth=_sourceWidth;
@property(copy, nonatomic) NSString *personLocalIdentifier; // @synthesize personLocalIdentifier=_personLocalIdentifier;
@property(readonly, copy, nonatomic) NSString *localIdentifier; // @synthesize localIdentifier=_localIdentifier;
- (double)photosFaceRepresentationQuality;	// IMP=0x000000000005a70e
- (double)photosFaceRepresentationRoll;	// IMP=0x000000000005a6fc
- (id)photosFaceRepresentationLocalIdentifier;	// IMP=0x000000000005a6ea
- (long long)photosFaceRepresentationClusterSequenceNumber;	// IMP=0x000000000005a6d8
- (long long)photosFaceRepresentationQualityMeasure;	// IMP=0x000000000005a6c6
- (_Bool)photosFaceRepresentationIsRightEyeClosed;	// IMP=0x000000000005a6b4
- (_Bool)photosFaceRepresentationIsLeftEyeClosed;	// IMP=0x000000000005a6a2
- (_Bool)photosFaceRepresentationHasSmile;	// IMP=0x000000000005a690
- (double)photosFaceRepresentationBlurScore;	// IMP=0x000000000005a67e
- (double)photosFaceRepresentationSize;	// IMP=0x000000000005a66c
- (double)photosFaceRepresentationCenterY;	// IMP=0x000000000005a65a
- (double)photosFaceRepresentationCenterX;	// IMP=0x000000000005a648
- (long long)photosFaceRepresentationSourceHeight;	// IMP=0x000000000005a636
- (long long)photosFaceRepresentationSourceWidth;	// IMP=0x000000000005a624
- (long long)qualityMeasureWithCountOfFacesOnAsset:(unsigned long long)arg1;	// IMP=0x000000000005a4c8
- (id)gist;	// IMP=0x0000000000059a43
- (struct CGRect)normalizedFaceRect;	// IMP=0x00000000000599c2
- (_Bool)setCenterAndSizeFromNormalizedFaceRect:(struct CGRect)arg1;	// IMP=0x0000000000059923
- (void)replaceCoordinatesAndFeaturesFromDetectedFace:(id)arg1;	// IMP=0x000000000005959e
- (id)initWithLocalIdentifier:(id)arg1;	// IMP=0x00000000000538f0

@end

